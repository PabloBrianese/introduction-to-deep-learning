{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dba60d2c-8de3-43cd-a7fa-00d54a960a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-04 13:54:48.281934: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-11-04 13:54:48.281978: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "534168d8-7ded-4c00-aff1-b09a78c2e6cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-04 13:54:49.631694: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-11-04 13:54:49.631732: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-11-04 13:54:49.631749: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (DESKTOP-FC4EGDV): /proc/driver/nvidia/version does not exist\n",
      "2021-11-04 13:54:49.631974: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Neural Network\n",
    "# Low level construction\n",
    "\n",
    "# Define inputs (features)\n",
    "inputs = tf.constant([[1.0, 35.0]])\n",
    "\n",
    "# Define weights\n",
    "weights = tf.Variable([[-0.05], [-0.01]])\n",
    "\n",
    "# Define the bias\n",
    "bias = tf.Variable([0.05])\n",
    "\n",
    "# Multiply inputs (features) by the weights\n",
    "product = tf.matmul(inputs, weights)\n",
    "\n",
    "# Define dense layer\n",
    "dense = tf.keras.activations.sigmoid(product + bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46958c77-53f5-48c2-982b-c918b0adf3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network\n",
    "# High level construction\n",
    "\n",
    "data = tf.ones([2, 2])  # esto consigue que compile, pero tendría que cambiar\n",
    "\n",
    "# Define input (features)\n",
    "inputs = tf.constant(data, tf.float32)\n",
    "\n",
    "# Define first dense layer\n",
    "dense1 = tf.keras.layers.Dense(10, activation='sigmoid')(inputs)\n",
    "\n",
    "# Define second dense layer\n",
    "dense2 = tf.keras.layers.Dense(5, activation='sigmoid')(dense1)\n",
    "\n",
    "# Define output (predictions) layer\n",
    "outputs = tf.keras.layers.Dense(1, activation='sigmoid')(dense2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdfc518c-f98b-4901-8ab6-c22b7fbc8c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction [[0.95257413]]\n",
      "actual 1\n"
     ]
    }
   ],
   "source": [
    "# Low level\n",
    "\n",
    "borrower_features = np.array([[ 2.,  2., 43.]], dtype=np.float32)\n",
    "\n",
    "# Initialize bias1\n",
    "bias1 = tf.Variable(1.0, dtype=tf.float32)\n",
    "\n",
    "# Initialize weights1 as 3x2 variable of ones\n",
    "weights1 = tf.Variable(np.ones([3,2]), dtype=tf.float32)\n",
    "\n",
    "# Perform matrix multiplication\n",
    "product1 = tf.matmul(borrower_features, weights1)\n",
    "\n",
    "# Apply sigmoid activation function to product1 + bias1\n",
    "dense1 = tf.keras.activations.sigmoid(product1 + bias1)\n",
    "\n",
    "# Initialize bias2 and weights2\n",
    "bias2 = tf.Variable(1.0, dtype=tf.float32)\n",
    "weights2 = tf.Variable(np.ones([2, 1]), dtype=tf.float32)\n",
    "\n",
    "# Perform matrix multiplication\n",
    "product2 = tf.matmul(dense1, weights2)\n",
    "\n",
    "# Apply activation to product2 + bias2 and print the prediction\n",
    "prediction = tf.keras.activations.sigmoid(product2 + bias2)\n",
    "\n",
    "print(f\"prediction {prediction.numpy()}\")\n",
    "print(\"actual 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13ac811a-736e-4d9a-bf6f-536606e13ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "borrower_features.shape=(5, 3)\n",
      "weights1.shape=TensorShape([3, 2])\n",
      "bias1.shape=TensorShape([])\n",
      "dense1.shape=TensorShape([5, 2])\n"
     ]
    }
   ],
   "source": [
    "borrower_features = np.array([[ 3.,  3., 23.],\n",
    "       [ 2.,  1., 24.],\n",
    "       [ 1.,  1., 49.],\n",
    "       [ 1.,  1., 49.],\n",
    "       [ 2.,  1., 29.]], dtype=np.float32)\n",
    "\n",
    "weights1 = tf.Variable(\n",
    "  np.array([[-0.6 ,  0.6 ],\n",
    "       [ 0.8 , -0.3 ],\n",
    "       [-0.09, -0.08]]), dtype=tf.float32)\n",
    "\n",
    "# Compute the product of borrower_features and weights1\n",
    "products1 = tf.matmul(borrower_features, weights1)\n",
    "\n",
    "# Apply a sigmoid activation function to products1 + bias1\n",
    "dense1 = tf.keras.activations.sigmoid(products1 + bias1)\n",
    "\n",
    "# Print the shapes of borrower_features, weights1, bias1, and dense1\n",
    "print(f\"{borrower_features.shape=}\")\n",
    "print(f\"{weights1.shape=}\")\n",
    "print(f\"{bias1.shape=}\")\n",
    "print(f\"{dense1.shape=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97941eaa-b0d6-433f-8cac-b06208126b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense1.shape=TensorShape([10, 7])\n",
      "dense2.shape=TensorShape([10, 3])\n",
      "predictions.shape=TensorShape([10, 1])\n"
     ]
    }
   ],
   "source": [
    "# High level\n",
    "\n",
    "# Data\n",
    "borrower_features = np.array([[0.6964692 , 0.28613934, 0.22685145, 0.5513148 , 0.71946895,\n",
    "        0.42310646, 0.9807642 , 0.6848297 , 0.4809319 , 0.39211753],\n",
    "       [0.343178  , 0.7290497 , 0.43857226, 0.0596779 , 0.39804426,\n",
    "        0.7379954 , 0.18249173, 0.17545176, 0.53155136, 0.53182757],\n",
    "       [0.63440096, 0.8494318 , 0.7244553 , 0.6110235 , 0.7224434 ,\n",
    "        0.32295892, 0.36178866, 0.22826323, 0.29371405, 0.63097614],\n",
    "       [0.09210494, 0.4337012 , 0.43086275, 0.4936851 , 0.4258303 ,\n",
    "        0.31226122, 0.4263513 , 0.89338917, 0.94416004, 0.50183666],\n",
    "       [0.6239529 , 0.11561839, 0.31728548, 0.4148262 , 0.86630917,\n",
    "        0.25045538, 0.48303425, 0.98555976, 0.5194851 , 0.61289454],\n",
    "       [0.12062866, 0.8263408 , 0.6030601 , 0.545068  , 0.34276384,\n",
    "        0.30412078, 0.4170222 , 0.68130076, 0.87545687, 0.51042235],\n",
    "       [0.6693138 , 0.58593655, 0.6249035 , 0.67468905, 0.84234244,\n",
    "        0.08319499, 0.76368284, 0.24366638, 0.19422296, 0.57245696],\n",
    "       [0.09571252, 0.8853268 , 0.62724894, 0.7234163 , 0.01612921,\n",
    "        0.5944319 , 0.55678517, 0.15895964, 0.15307051, 0.6955295 ],\n",
    "       [0.31876642, 0.6919703 , 0.5543833 , 0.3889506 , 0.9251325 ,\n",
    "        0.84167   , 0.35739756, 0.04359146, 0.3047681 , 0.39818567],\n",
    "       [0.70495886, 0.99535847, 0.35591486, 0.7625478 , 0.5931769 ,\n",
    "        0.69170177, 0.15112746, 0.39887628, 0.2408559 , 0.343456  ]],\n",
    "      dtype=np.float32)\n",
    "\n",
    "# Define first dense layer\n",
    "dense1 = tf.keras.layers.Dense(7, activation='sigmoid')(borrower_features)\n",
    "\n",
    "# Define a dense layer with 3 output nodes\n",
    "dense2 = tf.keras.layers.Dense(3, activation='sigmoid')(dense1)\n",
    "\n",
    "# Define a dense layer with 1 output node\n",
    "predictions = tf.keras.layers.Dense(1, activation='sigmoid')(dense2)\n",
    "\n",
    "# Print the shapes of dense1, dense2, and predictions\n",
    "print(f'{dense1.shape=}')\n",
    "print(f'{dense2.shape=}')\n",
    "print(f'{predictions.shape=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76947a3b-61a1-4265-9757-099099f7277c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# Activation functions ¿Why?\n",
    "\n",
    "# Define example borrower features\n",
    "young, old = 0.3, 0.6\n",
    "low_bill, high_bill = 0.1, 0.5\n",
    "\n",
    "# Apply matrix multiplication step for all feature combinations\n",
    "young_high = 1.0 * young + 2.0 * high_bill\n",
    "young_low = 1.0 * young + 2.0 * low_bill\n",
    "old_high = 1.0 * old + 2.0 * high_bill\n",
    "old_low = 1.0 * old + 2.0 * low_bill\n",
    "\n",
    "# Difference in default predictions for young\n",
    "young_diff = young_high - young_low\n",
    "\n",
    "# Difference in default predictions for old\n",
    "old_diff = old_high - old_low\n",
    "\n",
    "# Linear computations are not good enough to make predictions\n",
    "print(young_diff == old_diff)  # not good\n",
    "\n",
    "# Introduce nonlinearity\n",
    "from tensorflow.keras.activations import sigmoid\n",
    "\n",
    "# Difference in default predictions for young (non-linear)\n",
    "young_diff_nl = sigmoid(young_high) - sigmoid(young_low)\n",
    "\n",
    "# Difference in default predictions for old (non-linear)\n",
    "old_diff_nl = sigmoid(old_high) - sigmoid(old_low)\n",
    "\n",
    "# Non-linearities introduce good complexity into the model\n",
    "print((young_diff_nl == old_diff_nl).numpy())  # good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "759d5a80-7768-47c9-8abc-9b1decb117dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Define input layer\n",
    "inputs = tf.constant(borrower_features, tf.float32)\n",
    "\n",
    "# Define dense layer 1\n",
    "dense1 = Dense(16, activation='relu')(inputs)\n",
    "\n",
    "# Define dense layer 2\n",
    "dense2 = Dense(8, activation='sigmoid')(dense1)\n",
    "\n",
    "# Define output layer\n",
    "outputs = Dense(4, activation='softmax')(dense2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5499848-6368-4d44-8f60-f8c873557962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.],\n",
       "       [-1.],\n",
       "       [-1.],\n",
       "       [-1.],\n",
       "       [-1.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Untrained network\n",
    "\n",
    "# Features\n",
    "bill_amounts = np.array([[ 77479,  77057,  78102],\n",
    "       [   326,    326,    326],\n",
    "       [ 13686,   1992,    604],\n",
    "       [336722, 276725, 260932],\n",
    "       [231759, 233357, 236292],\n",
    "       [  1825,   2017,   2476],\n",
    "       [ 12136,   7938,    620],\n",
    "       [ 36159,  38241,  39121],\n",
    "       [205736, 199379, 132963],\n",
    "       [   692,     -6,    890]])\n",
    "\n",
    "# Target\n",
    "default = np.array([[0],\n",
    "       [0],\n",
    "       [0],\n",
    "       [0],\n",
    "       [0],\n",
    "       [0],\n",
    "       [0],\n",
    "       [0],\n",
    "       [1],\n",
    "       [0]])\n",
    "\n",
    "# Construct imput layer from features\n",
    "inputs = tf.constant(bill_amounts, tf.float32)\n",
    "\n",
    "# Define first dense layer\n",
    "dense1 = tf.keras.layers.Dense(3, activation='relu')(inputs)\n",
    "\n",
    "# Define second dense layer\n",
    "dense2 = tf.keras.layers.Dense(2, activation='relu')(dense1)\n",
    "\n",
    "# Define output layer\n",
    "outputs = tf.keras.layers.Dense(1, activation='sigmoid')(dense2)\n",
    "\n",
    "# Print error for first five examples\n",
    "error = default[:5] - outputs.numpy()[:5]\n",
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99f7ab8d-47fe-45a3-9a35-151e297abb09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.1621499  0.16891964 0.17174156 0.16348976 0.17454083 0.15915838]\n",
      " [0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667]\n",
      " [0.16460946 0.13786268 0.16842279 0.20009929 0.18186359 0.14714216]\n",
      " [0.15417656 0.17247207 0.1804868  0.15769449 0.188667   0.14650303]\n",
      " [0.16074038 0.16958669 0.17330706 0.1624823  0.17701629 0.15686728]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiclass classification problems\n",
    "\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Features\n",
    "borrower_features = np.array([[180201, 181443, 155045,  95145,  86025,   7000,   7000,   3100,\n",
    "         92101,   3200],\n",
    "       [ 12200,   8140,  10176,  20719,  15665,   1518,   5019,  15027,\n",
    "           639,    547],\n",
    "       [  1078,   5543,    500,    617,    617,   5562,    810,    617,\n",
    "             0,      0],\n",
    "       [  2422,    894,      0,      0,   1639,    894,      0,      0,\n",
    "          1639,    923],\n",
    "       [ 66380,  68083,  50822,  31179,  28686,   4000,   3012,   5000,\n",
    "          2000,   3000],\n",
    "       [   430,      0,  46257,  45975,   1300,      0,  46257,   2200,\n",
    "          1300,  43987],\n",
    "       [  1558,      0,    940,      0,    699,      0,    940,      0,\n",
    "           699,      0],\n",
    "       [150603, 153900,      0,      0,      0,   7000,      0,      0,\n",
    "             0,      0],\n",
    "       [    -5,    580,   2207,    630,    540,    585,   2207,    630,\n",
    "           540,      0],\n",
    "       [ 42372,  35580,  28330,  28136,  26752,   1500,   1800,   1088,\n",
    "          1200,   1200]])\n",
    "\n",
    "\n",
    "# Construct input layer from borrower features\n",
    "inputs = tf.constant(borrower_features, tf.float32)\n",
    "\n",
    "# Define first dense layer\n",
    "dense1 = Dense(10, activation='sigmoid')(inputs)\n",
    "\n",
    "# Define second dense layer\n",
    "dense2 = Dense(8, activation='relu')(dense1)\n",
    "\n",
    "# Define output layer\n",
    "outputs = Dense(6, activation='softmax')(dense2)\n",
    "\n",
    "# Print first five outputs\n",
    "print(outputs.numpy()[:5])\n",
    "\n",
    "# Print sum of all columns\n",
    "tf.reduce_sum(outputs, 1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2174f7c-4409-42e8-83a8-698f4f055aa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 1), dtype=float32, numpy=\n",
       "array([[111471.61   ],\n",
       "       [ -2891.168  ],\n",
       "       [  2115.7837 ],\n",
       "       [ -1185.4141 ],\n",
       "       [ 37566.15   ],\n",
       "       [ 12176.676  ],\n",
       "       [   165.06198],\n",
       "       [ 35832.105  ],\n",
       "       [  1601.697  ],\n",
       "       [ 17244.33   ]], dtype=float32)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.layers.Dense(1)(borrower_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c1bb1f2-7910-4041-906a-551468e86f3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ad0fe95f-89de-418b-a4e3-3e2156672f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.        0.        0.        0.        0.        0.        0.\n",
      "  0.       15.424949 -0.      ]\n",
      "[ 0.        0.        0.        0.        0.        0.        0.\n",
      "  0.       15.424949 -0.      ]\n",
      "[ 0.        0.        0.        0.        0.        0.        0.\n",
      "  0.       15.424949 -0.      ]\n",
      "[ 0.        0.        0.        0.        0.        0.        0.\n",
      "  0.       15.424949 -0.      ]\n",
      "[ 0.        0.        0.        0.        0.        0.        0.\n",
      "  0.       15.424949 -0.      ]\n",
      "[ 0.        0.        0.        0.        0.        0.        0.\n",
      "  0.       15.424949 -0.      ]\n",
      "[ 0.        0.        0.        0.        0.        0.        0.\n",
      "  0.       15.424949 -0.      ]\n",
      "[ 0.        0.        0.        0.        0.        0.        0.\n",
      "  0.       15.424949 -0.      ]\n",
      "[ 0.        0.        0.        0.        0.        0.        0.\n",
      "  0.       15.424949 -0.      ]\n",
      "[ 0.        0.        0.        0.        0.        0.        0.\n",
      "  0.       15.424949 -0.      ]\n"
     ]
    }
   ],
   "source": [
    "# Optimizers\n",
    "\n",
    "from tensorflow.keras.activations import sigmoid\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "bias = tf.Variable(tf.random.normal([1]))\n",
    "weights = tf.Variable(tf.random.normal([1, 10]))\n",
    "\n",
    "# Define the model function\n",
    "def model(bias, weights, features=borrower_features):\n",
    "  return tf.transpose(sigmoid(bias + weights @ features))\n",
    "\n",
    "\n",
    "# Compute the predicted values and loss\n",
    "def loss_function(bias, weights, targets=default, features=borrower_features):\n",
    "  predictions = model(bias, weights, features)\n",
    "  return binary_crossentropy(targets, predictions)\n",
    "\n",
    "\n",
    "# Minimize the loss function with RMS propagation\n",
    "opt = RMSprop(learning_rate=0.01, momentum=0.9)\n",
    "for j in range(1000):\n",
    "  opt.minimize(lambda: loss_function(bias, weights), var_list=[bias, weights])\n",
    "  \n",
    "  if not j % 100: print(loss_function(bias, weights).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bd0b3e-7ddb-42d1-a470-61e762d8d17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dangers of local minima\n",
    "\n",
    "# Loss function with two local minima\n",
    "def loss_function(x):\n",
    "  return (abs(x) + 1) * abs(x - 7)\n",
    "\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "# Initialize x_1 and x_2\n",
    "x_1 = tf.Variable(6.0, tf.float32)\n",
    "x_2 = tf.Variable(0.3, tf.float32)\n",
    "\n",
    "# Define the optimization operation\n",
    "opt = SGD(learning_rate=0.01)\n",
    "\n",
    "# Perform minimization using the loss function and x_1\n",
    "for j in range(100):\n",
    "  opt.minimize(lambda: loss_function(x_1), var_list=[x_1])\n",
    "\n",
    "# Perform minimization using the loss function and x_2\n",
    "for j in range(100):\n",
    "  opt.minimize(lambda: loss_function(x_2), var_list=[x_2])\n",
    "\n",
    "# Compare x_1 and x_2\n",
    "print(x_1.numpy(), x_2.numpy())\n",
    "\n",
    "# Observe the loss function to understand why minimization results diverge\n",
    "from matplotlib import pyplot as plt\n",
    "xs = np.linspace(-1, 8)\n",
    "plt.plot(xs, [loss_function(x) for x in xs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661dcb03-94f4-4005-b3b2-10b098204f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Momentum avoids local minima\n",
    "\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "# Initialize x_1 and x_2\n",
    "x_1 = tf.Variable(-2.0, tf.float32)\n",
    "x_2 = tf.Variable(-2.0, tf.float32)\n",
    "\n",
    "# Define the optimization operation for opt_1 and opt_2\n",
    "opt_1 = RMSprop(learning_rate=0.01, momentum=0.99)\n",
    "opt_2 = RMSprop(learning_rate=0.01, momentum=0.00)\n",
    "\n",
    "# Perform minimization using the loss function and x_1\n",
    "for j in range(1000):\n",
    "  opt_1.minimize(lambda: loss_function(x_1), var_list=[x_1])\n",
    "  \n",
    "# Perform minimization using the loss function and x_2\n",
    "for j in range(1000):\n",
    "  opt_2.minimize(lambda: loss_function(x_2), var_list=[x_2])\n",
    "\n",
    "# Compare x_1 and x_2\n",
    "print(x_1.numpy(), x_2.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a356f9bb-baf7-48f8-8a45-098928722cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization\n",
    "\n",
    "# Define the layer 1 weights\n",
    "w1 = tf.Variable(tf.random.normal([23, 7]))\n",
    "\n",
    "# Initialize the layer 1 bias\n",
    "b1 = tf.Variable(tf.ones([7]))\n",
    "\n",
    "# Define the layer 2 weights\n",
    "w2 = tf.Variable(tf.random.normal([7, 1]))\n",
    "\n",
    "# Define the layer 2 bias\n",
    "b2 = tf.Variable(0.0)\n",
    "\n",
    "# Define the model\n",
    "def model(w1, b1, w2, b2, features=borrower_features):\n",
    "  # Apply relu activation functions to layer 1\n",
    "  layer1 = tf.keras.activations.relu(tf.matmul(features, w1) + b1)\n",
    "  # Apply dropout rate of 0.25\n",
    "  dropout = tf.keras.layers.Dropout(0.25)(layer1)\n",
    "  return tf.keras.activations.sigmoid(tf.matmul(dropout, w2) + b2)\n",
    "\n",
    "\n",
    "# Define the loss function\n",
    "def loss_function(w1, b1, w2, b2, features=borrower_features, targets=default):\n",
    "  predictions = model(w1, b1, w2, b2)\n",
    "  # Pass targets and predictions to the cross entropy loss\n",
    "  return tf.keras.losses.binary_crossentropy(targets, predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
